# Modelos Predictivos - Fase 2

Sistema de modelos de machine learning con entrenamiento autom√°tico, optimizaci√≥n Bayesiana y selecci√≥n basada en rMAPE.

## üìã Contenido

```
models/
‚îú‚îÄ‚îÄ __init__.py                 # Exports principales
‚îú‚îÄ‚îÄ metrics.py                  # M√©tricas (rMAPE, MAPE, correlaci√≥n)
‚îú‚îÄ‚îÄ base_models.py              # Modelos: XGBoost, LightGBM, RandomForest
‚îú‚îÄ‚îÄ model_trainer.py            # Sistema de entrenamiento autom√°tico
‚îú‚îÄ‚îÄ model_registry.py           # Versionado y gesti√≥n de modelos
‚îî‚îÄ‚îÄ README.md                   # Esta documentaci√≥n
```

---

## üéØ M√©tricas Implementadas

### rMAPE (Novel Metric)

**M√©trica propuesta por Universidad del Norte (IEEE Access 2023)**

```python
rMAPE = MAPE / r_xy
```

Donde:
- `MAPE` = Mean Absolute Percentage Error
- `r_xy` = Coeficiente de correlaci√≥n de Pearson

**¬øPor qu√© es mejor que MAPE?**

| Escenario | MAPE | rMAPE | Interpretaci√≥n |
|-----------|------|-------|----------------|
| Predicci√≥n perfecta | Bajo | Bajo | ‚úÖ Excelente |
| MAPE bajo + forma incorrecta | Bajo | Alto | ‚ùå Mala predicci√≥n |
| MAPE alto | Alto | Alto | ‚ùå Mala predicci√≥n |

rMAPE captura **magnitud Y forma** de la curva predicha.

---

## ü§ñ Modelos Implementados

### 1. XGBoost (Extreme Gradient Boosting)

**Estado del arte para datos tabulares**

- ‚úÖ Mejor performance esperado
- ‚úÖ Feature importance nativo
- ‚úÖ Regularizaci√≥n autom√°tica
- ‚ö° R√°pido de entrenar

```python
from models.base_models import XGBoostModel

model = XGBoostModel(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05
)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
```

### 2. LightGBM (Light Gradient Boosting Machine)

**M√°s r√°pido que XGBoost, similar performance**

- ‚ö° Hasta 10x m√°s r√°pido que XGBoost
- ‚úÖ Ideal para reentrenamiento autom√°tico frecuente
- ‚úÖ Menos memoria
- ‚úÖ Maneja features categ√≥ricas nativamente

```python
from models.base_models import LightGBMModel

model = LightGBMModel(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05
)
```

### 3. Random Forest

**Modelo robusto usado como fallback**

- ‚úÖ Muy robusto (no overfitting f√°cilmente)
- ‚úÖ No requiere escalado de features
- ‚úÖ F√°cil de interpretar
- ‚úÖ Funciona "out of the box"

```python
from models.base_models import RandomForestModel

model = RandomForestModel(
    n_estimators=200,
    max_depth=15
)
```

---

## üéì Sistema de Entrenamiento

### Caracter√≠sticas

- ‚úÖ **Entrenamiento autom√°tico** de m√∫ltiples modelos
- ‚úÖ **Optimizaci√≥n Bayesiana** de hiperpar√°metros (opcional)
- ‚úÖ **Validaci√≥n cruzada temporal** (Time Series Split)
- ‚úÖ **Selecci√≥n autom√°tica** del mejor modelo basado en rMAPE
- ‚úÖ **Feature importance** autom√°tico

### Uso B√°sico

```python
from models.model_trainer import ModelTrainer

# Crear entrenador
trainer = ModelTrainer(
    optimize_hyperparams=False,  # True para optimizaci√≥n Bayesiana
    cv_splits=3
)

# Entrenar todos los modelos
trained_models = trainer.train_all_models(
    X_train, y_train,
    X_val, y_val,
    models=['xgboost', 'lightgbm', 'randomforest']
)

# Seleccionar mejor modelo
best_name, best_model, best_results = trainer.select_best_model(
    criterion='rmape',
    use_validation=True
)

# Guardar todos los modelos
trainer.save_all_models()
```

### Con Optimizaci√≥n Bayesiana

```python
# Habilitar optimizaci√≥n Bayesiana (m√°s lento pero mejor)
trainer = ModelTrainer(
    optimize_hyperparams=True,
    n_optimization_iter=20  # N√∫mero de iteraciones
)

trained_models = trainer.train_all_models(X_train, y_train)
```

---

## üì¶ Model Registry

Sistema de versionado y gesti√≥n de modelos entrenados.

### Caracter√≠sticas

- ‚úÖ Registro de todos los modelos con m√©tricas
- ‚úÖ Selecci√≥n autom√°tica del "modelo campe√≥n"
- ‚úÖ Historial completo de cambios
- ‚úÖ Rollback al campe√≥n anterior
- ‚úÖ Limpieza autom√°tica de modelos antiguos

### Uso

```python
from models.model_registry import ModelRegistry

# Crear registry
registry = ModelRegistry()

# Registrar modelo
model_id = registry.register_model(
    model=trained_model,
    model_name='xgboost',
    metrics={'rmape': 3.5, 'mape': 0.8},
    metadata={'training_time': 45.2}
)

# Seleccionar y promocionar mejor modelo a campe√≥n
champion_id = registry.select_best_and_promote(criterion='rmape')

# Cargar modelo campe√≥n
champion_model = registry.load_champion_model()

# Ver todos los modelos registrados
df_models = registry.get_all_models()
print(df_models[['model_id', 'rmape', 'mape', 'is_champion']])

# Rollback si el nuevo campe√≥n no funciona
registry.rollback_to_previous_champion()
```

---

## üöÄ Entrenamiento Completo

### Script Principal

```bash
python train_models.py
```

Este script:

1. ‚úÖ Carga datos de `data/features/data_with_features_latest.csv`
2. ‚úÖ Prepara datos (split temporal 80/20)
3. ‚úÖ Entrena los 3 modelos (XGBoost, LightGBM, RandomForest)
4. ‚úÖ Realiza validaci√≥n cruzada temporal
5. ‚úÖ Selecciona el mejor modelo basado en rMAPE
6. ‚úÖ Eval√∫a cumplimiento regulatorio (MAPE < 5%)
7. ‚úÖ Registra todos los modelos en el registry
8. ‚úÖ Promociona el mejor a "campe√≥n"
9. ‚úÖ Guarda modelos y predicciones

### Salida del Script

```
================================================================================
SISTEMA DE ENTRENAMIENTO AUTOM√ÅTICO DE MODELOS - FASE 2
================================================================================

1. CARGANDO DATOS
  ‚úì Datos cargados: 3,226 registros

2. PREPARANDO DATOS
  Features disponibles: 63
  Target: TOTAL

3. SPLIT TEMPORAL
  Train set: 2,580 registros
  Test set: 646 registros

4. ENTRENAMIENTO DE MODELOS
  Entrenando XGBOOST...
    ‚úì Train MAPE: 0.12%
    ‚úì Val MAPE: 0.45%

  Entrenando LIGHTGBM...
    ‚úì Train MAPE: 0.15%
    ‚úì Val MAPE: 0.52%

  Entrenando RANDOMFOREST...
    ‚úì Train MAPE: 0.89%
    ‚úì Val MAPE: 1.23%

5. COMPARACI√ìN DE MODELOS
  XGBOOST       0.12%     0.45%      2.1234     3.5678     0.9456
  LIGHTGBM      0.15%     0.52%      2.3456     3.8901     0.9423
  RANDOMFOREST  0.89%     1.23%      4.5678     6.7890     0.9345

6. MEJOR MODELO SELECCIONADO: XGBOOST

7. EVALUACI√ìN FINAL EN TEST SET
  MAPE: 0.45%
  rMAPE: 3.56
  R¬≤: 0.946
  ‚úÖ CUMPLE regulaci√≥n (MAPE < 5%)

8. REGISTRANDO MODELOS
  ‚úì xgboost_20241120_153045
  ‚úì lightgbm_20241120_153045
  ‚úì randomforest_20241120_153045

  üèÜ NUEVO MODELO CAMPE√ìN: xgboost_20241120_153045

‚úÖ ENTRENAMIENTO COMPLETADO EXITOSAMENTE
```

---

## üìä Archivos Generados

Despu√©s de ejecutar `train_models.py`:

```
models/
‚îú‚îÄ‚îÄ trained/
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_20241120_153045.joblib
‚îÇ   ‚îú‚îÄ‚îÄ lightgbm_20241120_153045.joblib
‚îÇ   ‚îú‚îÄ‚îÄ randomforest_20241120_153045.joblib
‚îÇ   ‚îî‚îÄ‚îÄ training_results_20241120_153045.json
‚îÇ
‚îî‚îÄ‚îÄ registry/
    ‚îú‚îÄ‚îÄ registry_metadata.json
    ‚îú‚îÄ‚îÄ champion_model.joblib
    ‚îú‚îÄ‚îÄ xgboost_20241120_153045.joblib
    ‚îú‚îÄ‚îÄ lightgbm_20241120_153045.joblib
    ‚îî‚îÄ‚îÄ randomforest_20241120_153045.joblib

data/features/
‚îú‚îÄ‚îÄ predictions_20241120_153045.csv
‚îî‚îÄ‚îÄ feature_importance_20241120_153045.csv
```

---

## üî¨ Testing de Componentes

### Test de M√©tricas

```bash
python models/metrics.py
```

### Test de Modelos Base

```bash
python models/base_models.py
```

### Test de Model Registry

```bash
python models/model_registry.py
```

---

## üìà Performance Esperado

Basado en tu prototipo (MAPE 0.45%):

| Modelo | MAPE Esperado | rMAPE Esperado | Tiempo Entrenamiento |
|--------|---------------|----------------|---------------------|
| XGBoost | 0.3% - 0.6% | 3 - 5 | 10-30s |
| LightGBM | 0.4% - 0.7% | 3.5 - 5.5 | 5-15s |
| RandomForest | 0.8% - 1.5% | 5 - 8 | 5-10s |

**Objetivo Regulatorio:** MAPE < 5% ‚úÖ Todos cumplen

---

## üéì Ejemplo Completo

```python
# 1. Cargar datos
import pandas as pd
from pathlib import Path

data_path = Path("data/features/data_with_features_latest.csv")
df = pd.read_csv(data_path)

# 2. Preparar datos
exclude_cols = ['FECHA', 'TOTAL'] + [f'P{i}' for i in range(1, 25)]
feature_cols = [col for col in df.columns if col not in exclude_cols]

X = df[feature_cols].fillna(0)
y = df['TOTAL'].dropna()

# 3. Split temporal
split_idx = int(len(X) * 0.8)
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

# 4. Entrenar modelos
from models.model_trainer import ModelTrainer

trainer = ModelTrainer(optimize_hyperparams=False)
trained_models = trainer.train_all_models(
    X_train, y_train, X_test, y_test
)

# 5. Seleccionar mejor
best_name, best_model, best_results = trainer.select_best_model(
    criterion='rmape'
)

# 6. Predecir
y_pred = best_model.predict(X_test)

# 7. Evaluar
from models.metrics import evaluate_model_performance

evaluation = evaluate_model_performance(y_test, y_pred)
print(f"MAPE: {evaluation['metrics']['mape']:.2f}%")
print(f"rMAPE: {evaluation['metrics']['rmape']:.2f}")
print(f"Cumple: {evaluation['regulatory_compliance']['cumple_mape_5pct']}")

# 8. Registrar en registry
from models.model_registry import ModelRegistry

registry = ModelRegistry()
model_id = registry.register_model(
    model=best_model,
    model_name=best_name,
    metrics=evaluation['metrics']
)

registry.promote_to_champion(model_id)
```

---

## üîß Configuraci√≥n Avanzada

### Personalizar Hiperpar√°metros

```python
from models.base_models import XGBoostModel

model = XGBoostModel(
    n_estimators=500,        # M√°s √°rboles
    max_depth=8,             # √Årboles m√°s profundos
    learning_rate=0.03,      # Learning rate m√°s bajo
    subsample=0.9,
    colsample_bytree=0.9,
    min_child_weight=5,
    gamma=0.2,
    reg_alpha=0.2,
    reg_lambda=1.5
)
```

### Optimizaci√≥n Bayesiana Personalizada

```python
trainer = ModelTrainer(
    optimize_hyperparams=True,
    n_optimization_iter=50,  # M√°s iteraciones = mejor optimizaci√≥n
    cv_splits=5              # M√°s folds = validaci√≥n m√°s robusta
)
```

---

## üìù Notas Importantes

1. **Optimizaci√≥n Bayesiana:** Es lenta pero encuentra mejores hiperpar√°metros. Usar solo cuando se necesita m√°ximo performance.

2. **rMAPE vs MAPE:** Siempre usar rMAPE para selecci√≥n de modelos. El MAPE puede ser enga√±oso.

3. **Model Registry:** Siempre registrar modelos antes de promocionarlos a campe√≥n.

4. **Fallback:** Random Forest es el modelo de fallback si XGBoost/LightGBM fallan.

5. **Reentrenamiento:** Los modelos deben reentrenarse cuando rMAPE > umbral (implementar en Auditor).

---

## üöÄ Pr√≥ximos Pasos

- [ ] Implementar sistema Auditor (monitoreo + reentrenamiento autom√°tico)
- [ ] Crear API Gateway REST
- [ ] Implementar predicci√≥n por per√≠odo horario (P1-P24)
- [ ] Desagregaci√≥n a 15 minutos

---

**Desarrollado para EPM - Empresas P√∫blicas de Medell√≠n**
**Fecha:** Noviembre 2024
