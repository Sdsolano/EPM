"""
Dashboard de Predicci√≥n - EPM
==============================

Dashboard Streamlit para generar predicciones de demanda energ√©tica.
Permite seleccionar ciudad, fechas, n√∫mero de d√≠as y opci√≥n de retrain.
Muestra gr√°ficas comparando predicciones vs datos hist√≥ricos.

Utiliza la API directamente mediante llamadas HTTP.

Uso:
    streamlit run dashboards/prediction_api_dashboard.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timedelta
from pathlib import Path
import sys
import logging
import requests
from typing import Optional, Dict, Any

# Agregar src al path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config.settings import RAW_DATA_DIR

# Configurar logging
logging.basicConfig(level=logging.WARNING)

# Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="Predicci√≥n - EPM",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        font-weight: bold;
    }
    .stButton>button:hover {
        background-color: #1565c0;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# CONFIGURACI√ìN DE API
# ============================================================================

# URL base de la API (configurable)
DEFAULT_API_URL = "http://localhost:8000"

# ============================================================================
# FUNCIONES DE CARGA DE DATOS HIST√ìRICOS
# ============================================================================

@st.cache_data
def load_historical_data_for_comparison(ucp: str):
    """
    Carga datos hist√≥ricos para comparaci√≥n visual.
    
    Args:
        ucp: Nombre del UCP ('Atlantico' o 'Antioquia')
    
    Returns:
        DataFrame con datos hist√≥ricos o None si no existe
    """
    # Intentar cargar desde datos procesados con features
    ucp_path = Path(f'data/features/{ucp}/data_with_features_latest.csv')
    if ucp_path.exists():
        try:
            df = pd.read_csv(ucp_path)
            if 'FECHA' in df.columns:
                df['FECHA'] = pd.to_datetime(df['FECHA'])
                df = df.sort_values('FECHA')
                return df
        except Exception as e:
            st.warning(f"Error cargando datos procesados: {e}")
    
    # Fallback: intentar datos raw
    path = RAW_DATA_DIR / ucp / "datos.csv"
    if not path.exists():
        path = RAW_DATA_DIR / "datos.csv"
    
    if path.exists():
        try:
            df = pd.read_csv(path)
            if 'FECHA' in df.columns:
                df['FECHA'] = pd.to_datetime(df['FECHA'])
                df = df.sort_values('FECHA')
                if 'UCP' in df.columns:
                    ucp_mapping = {
                        'Atlantico': 'Atlantico',
                        'Antioquia': 'UANTIOQUIA'
                    }
                    ucp_in_data = ucp_mapping.get(ucp, ucp)
                    df = df[df['UCP'].str.upper() == ucp_in_data.upper()]
                return df
        except Exception as e:
            st.warning(f"Error cargando datos hist√≥ricos: {e}")
    
    return None


def get_historical_total(df_historico, fecha_inicio, fecha_fin):
    """
    Extrae datos hist√≥ricos de TOTAL para un rango de fechas
    
    Args:
        df_historico: DataFrame con datos hist√≥ricos
        fecha_inicio: Fecha inicio (datetime)
        fecha_fin: Fecha fin (datetime)
    
    Returns:
        DataFrame con columnas: fecha, demanda_total
    """
    if df_historico is None or len(df_historico) == 0:
        return pd.DataFrame()
    
    # Filtrar por rango de fechas
    mask = (df_historico['FECHA'] >= fecha_inicio) & (df_historico['FECHA'] <= fecha_fin)
    df_filtered = df_historico[mask].copy()
    
    if len(df_filtered) == 0:
        return pd.DataFrame()
    
    # Normalizar nombre de columna TOTAL
    total_col = 'TOTAL' if 'TOTAL' in df_filtered.columns else 'demanda_total'
    if total_col not in df_filtered.columns:
        # Intentar calcular desde columnas P1-P24
        period_cols = [f'P{i}' for i in range(1, 25)]
        if all(col in df_filtered.columns for col in period_cols):
            df_filtered['TOTAL'] = df_filtered[period_cols].sum(axis=1)
            total_col = 'TOTAL'
        else:
            return pd.DataFrame()
    
    # Crear DataFrame de salida
    result = pd.DataFrame({
        'fecha': df_filtered['FECHA'],
        'demanda_total': df_filtered[total_col]
    })
    
    return result.sort_values('fecha')


# ============================================================================
# FUNCIONES DE LLAMADAS A LA API
# ============================================================================

def call_predict_api(api_url: str, ucp: str, n_days: int, end_date: Optional[str] = None, force_retrain: bool = False, offset_scalar: Optional[float] = None) -> Dict[str, Any]:
    """
    Llama al endpoint /predict de la API
    
    Args:
        api_url: URL base de la API
        ucp: Nombre del UCP
        n_days: N√∫mero de d√≠as a predecir
        end_date: Fecha final de datos hist√≥ricos (formato YYYY-MM-DD)
        force_retrain: Forzar reentrenamiento
        offset_scalar: Escalar opcional para ajustar todas las predicciones (ej: 1.2 para aumentar 20%)
    
    Returns:
        Dict con la respuesta de la API o None si hay error
    """
    url = f"{api_url}/predict"
    
    payload = {
        "ucp": ucp,
        "n_days": n_days,
        "force_retrain": force_retrain
    }
    
    if end_date:
        payload["end_date"] = end_date
    
    if offset_scalar is not None and offset_scalar > 0:
        payload["offset_scalar"] = offset_scalar
    
    try:
        response = requests.post(url, json=payload, timeout=600)  # 10 minutos timeout
        response.raise_for_status()
        return response.json()
    except requests.exceptions.ConnectionError:
        return {"error": f"No se pudo conectar a la API en {api_url}. Aseg√∫rate de que el servidor est√© corriendo."}
    except requests.exceptions.Timeout:
        return {"error": "La solicitud a la API tard√≥ demasiado. Intenta nuevamente."}
    except requests.exceptions.HTTPError as e:
        try:
            error_detail = response.json().get("detail", str(e))
            return {"error": f"Error HTTP {response.status_code}: {error_detail}"}
        except:
            return {"error": f"Error HTTP {response.status_code}: {str(e)}"}
    except Exception as e:
        return {"error": f"Error inesperado: {str(e)}"}


def call_retrain_api(api_url: str, ucp: str) -> Dict[str, Any]:
    """
    Llama al endpoint /retrain de la API
    
    Args:
        api_url: URL base de la API
        ucp: Nombre del UCP
    
    Returns:
        Dict con la respuesta de la API o None si hay error
    """
    url = f"{api_url}/retrain"
    
    try:
        response = requests.post(url, params={"ucp": ucp}, timeout=600)  # 10 minutos timeout
        response.raise_for_status()
        return response.json()
    except requests.exceptions.ConnectionError:
        return {"error": f"No se pudo conectar a la API en {api_url}. Aseg√∫rate de que el servidor est√© corriendo."}
    except requests.exceptions.Timeout:
        return {"error": "La solicitud a la API tard√≥ demasiado. Intenta nuevamente."}
    except requests.exceptions.HTTPError as e:
        try:
            error_detail = response.json().get("detail", str(e))
            return {"error": f"Error HTTP {response.status_code}: {error_detail}"}
        except:
            return {"error": f"Error HTTP {response.status_code}: {str(e)}"}
    except Exception as e:
        return {"error": f"Error inesperado: {str(e)}"}


def call_base_curve_api(api_url: str, ucp: str, fecha_inicio: str, fecha_fin: str) -> Dict[str, Any]:
    """
    Llama al endpoint /api/v1/base-curve de la API
    
    Args:
        api_url: URL base de la API
        ucp: Nombre del UCP
        fecha_inicio: Fecha inicio (formato YYYY-MM-DD)
        fecha_fin: Fecha fin (formato YYYY-MM-DD)
    
    Returns:
        Dict con la respuesta de la API o None si hay error
    """
    url = f"{api_url}/base-curve"
    
    payload = {
        "ucp": ucp,
        "fecha_inicio": fecha_inicio,
        "fecha_fin": fecha_fin
    }
    
    try:
        response = requests.post(url, json=payload, timeout=300)  # 5 minutos timeout
        response.raise_for_status()
        return response.json()
    except requests.exceptions.ConnectionError:
        return {"error": f"No se pudo conectar a la API en {api_url}. Aseg√∫rate de que el servidor est√© corriendo."}
    except requests.exceptions.Timeout:
        return {"error": "La solicitud a la API tard√≥ demasiado. Intenta nuevamente."}
    except requests.exceptions.HTTPError as e:
        try:
            error_detail = response.json().get("detail", str(e))
            return {"error": f"Error HTTP {response.status_code}: {error_detail}"}
        except:
            return {"error": f"Error HTTP {response.status_code}: {str(e)}"}
    except Exception as e:
        return {"error": f"Error inesperado: {str(e)}"}


def check_api_health(api_url: str) -> bool:
    """
    Verifica si la API est√° disponible
    
    Args:
        api_url: URL base de la API
    
    Returns:
        True si la API est√° disponible, False en caso contrario
    """
    try:
        response = requests.get(f"{api_url}/health", timeout=5)
        return response.status_code == 200
    except:
        return False


def convert_predictions_to_dataframe(api_response: Dict[str, Any]) -> Optional[pd.DataFrame]:
    """
    Convierte la respuesta de la API a un DataFrame de predicciones
    
    Args:
        api_response: Respuesta JSON de la API
    
    Returns:
        DataFrame con predicciones o None si hay error
    """
    if "error" in api_response:
        return None
    
    if "predictions" not in api_response:
        return None
    
    predictions = api_response["predictions"]
    
    if not predictions or len(predictions) == 0:
        return None
    
    # Convertir lista de predicciones a DataFrame
    rows = []
    for pred in predictions:
        fecha = pred.get("fecha")
        demanda_predicha = pred.get("demanda_predicha") or pred.get("demanda_total")
        
        if fecha and demanda_predicha is not None:
            rows.append({
                "fecha": pd.to_datetime(fecha),
                "demanda_predicha": demanda_predicha,
                "demanda_total": demanda_predicha  # Alias para compatibilidad
            })
    
    if len(rows) == 0:
        return None
    
    df = pd.DataFrame(rows)
    df = df.sort_values("fecha")
    return df


def convert_predictions_to_hourly_dataframe(api_response: Dict[str, Any]) -> Optional[pd.DataFrame]:
    """
    Convierte la respuesta de la API a un DataFrame con datos horarios (P1-P24)
    
    Args:
        api_response: Respuesta JSON de la API
    
    Returns:
        DataFrame con columnas: fecha_hora, demanda_horaria, tipo (prediccion/historico)
    """
    if "error" in api_response:
        return None
    
    if "predictions" not in api_response:
        return None
    
    predictions = api_response["predictions"]
    
    if not predictions or len(predictions) == 0:
        return None
    
    # Convertir lista de predicciones a DataFrame horario
    rows = []
    for pred in predictions:
        fecha_str = pred.get("fecha")
        if not fecha_str:
            continue
        
        fecha = pd.to_datetime(fecha_str)
        
        # Extraer per√≠odos P1-P24
        for periodo in range(1, 25):
            periodo_key = f"P{periodo}"
            if periodo_key in pred:
                # Crear datetime con la hora correspondiente (periodo 1 = 00:00, periodo 2 = 01:00, etc.)
                # Los per√≠odos van de 00:00-01:00 (P1) a 23:00-00:00 (P24)
                hora = periodo - 1  # P1 = 0, P2 = 1, ..., P24 = 23
                fecha_hora = fecha.replace(hour=hora, minute=0, second=0)
                
                rows.append({
                    "fecha_hora": fecha_hora,
                    "demanda_horaria": pred[periodo_key],
                    "tipo": "prediccion",
                    "periodo": periodo
                })
    
    if len(rows) == 0:
        return None
    
    df = pd.DataFrame(rows)
    df = df.sort_values("fecha_hora")
    return df


def get_historical_hourly_data(df_historico, fecha_inicio, fecha_fin):
    """
    Extrae datos hist√≥ricos horarios (P1-P24) para un rango de fechas
    
    Args:
        df_historico: DataFrame con datos hist√≥ricos (debe tener columnas P1-P24)
        fecha_inicio: Fecha inicio (datetime)
        fecha_fin: Fecha fin (datetime)
    
    Returns:
        DataFrame con columnas: fecha_hora, demanda_horaria, tipo
    """
    if df_historico is None or len(df_historico) == 0:
        return pd.DataFrame()
    
    # Filtrar por rango de fechas
    mask = (df_historico['FECHA'] >= fecha_inicio) & (df_historico['FECHA'] <= fecha_fin)
    df_filtered = df_historico[mask].copy()
    
    if len(df_filtered) == 0:
        return pd.DataFrame()
    
    # Verificar que tenga columnas P1-P24
    period_cols = [f'P{i}' for i in range(1, 25)]
    if not all(col in df_filtered.columns for col in period_cols):
        return pd.DataFrame()
    
    # Convertir a formato horario
    rows = []
    for _, row in df_filtered.iterrows():
        fecha = pd.to_datetime(row['FECHA'])
        
        for periodo in range(1, 25):
            periodo_key = f'P{periodo}'
            if periodo_key in row and pd.notna(row[periodo_key]):
                hora = periodo - 1  # P1 = 0, P2 = 1, ..., P24 = 23
                fecha_hora = fecha.replace(hour=hora, minute=0, second=0)
                
                rows.append({
                    "fecha_hora": fecha_hora,
                    "demanda_horaria": row[periodo_key],
                    "tipo": "historico",
                    "periodo": periodo
                })
    
    if len(rows) == 0:
        return pd.DataFrame()
    
    df = pd.DataFrame(rows)
    df = df.sort_values("fecha_hora")
    return df


# ============================================================================
# FUNCIONES DE VISUALIZACI√ìN
# ============================================================================

def plot_predictions_vs_historical(predictions_df, historical_df, title="Predicciones vs Hist√≥ricos"):
    """
    Crea gr√°fica comparando predicciones con datos hist√≥ricos
    
    Args:
        predictions_df: DataFrame con predicciones (debe tener 'fecha' y 'demanda_predicha' o 'demanda_total')
        historical_df: DataFrame con datos hist√≥ricos (debe tener 'fecha' y 'demanda_total')
        title: T√≠tulo de la gr√°fica
    
    Returns:
        Figura de Plotly
    """
    fig = go.Figure()
    
    # Agregar l√≠nea de predicciones
    if predictions_df is not None and len(predictions_df) > 0:
        # Convertir fecha si es necesario
        pred_dates = pd.to_datetime(predictions_df['fecha'])
        # Intentar diferentes nombres de columna para demanda
        if 'demanda_predicha' in predictions_df.columns:
            pred_values = predictions_df['demanda_predicha']
        elif 'demanda_total' in predictions_df.columns:
            pred_values = predictions_df['demanda_total']
        elif 'TOTAL' in predictions_df.columns:
            pred_values = predictions_df['TOTAL']
        else:
            pred_values = None
        
        if pred_values is not None:
            fig.add_trace(go.Scatter(
                x=pred_dates,
                y=pred_values,
                mode='lines+markers',
                name='Predicci√≥n',
                line=dict(color='#ff7f0e', width=3),
                marker=dict(size=6),
                hovertemplate='<b>%{x|%Y-%m-%d}</b><br>Predicci√≥n: %{y:,.0f} MWh<extra></extra>'
            ))
    
    # Agregar l√≠nea de datos hist√≥ricos
    if historical_df is not None and len(historical_df) > 0:
        hist_dates = pd.to_datetime(historical_df['fecha'])
        hist_values = historical_df['demanda_total']
        
        fig.add_trace(go.Scatter(
            x=hist_dates,
            y=hist_values,
            mode='lines+markers',
            name='Hist√≥rico Real',
            line=dict(color='#1f77b4', width=3),
            marker=dict(size=6),
            hovertemplate='<b>%{x|%Y-%m-%d}</b><br>Real: %{y:,.0f} MWh<extra></extra>'
        ))
    
    # Configurar layout
    fig.update_layout(
        title=dict(
            text=title,
            font=dict(size=20, color='#1f77b4')
        ),
        xaxis=dict(
            title='Fecha',
            showgrid=True,
            gridcolor='lightgray'
        ),
        yaxis=dict(
            title='Demanda (MWh)',
            showgrid=True,
            gridcolor='lightgray'
        ),
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        height=500,
        template='plotly_white'
    )
    
    return fig


def plot_hourly_predictions_vs_historical(hourly_predictions_df, hourly_historical_df, title="Predicciones Horarias vs Hist√≥ricos"):
    """
    Crea gr√°fica comparando predicciones horarias con datos hist√≥ricos horarios
    
    Args:
        hourly_predictions_df: DataFrame con predicciones horarias (debe tener 'fecha_hora' y 'demanda_horaria')
        hourly_historical_df: DataFrame con datos hist√≥ricos horarios (debe tener 'fecha_hora' y 'demanda_horaria')
        title: T√≠tulo de la gr√°fica
    
    Returns:
        Figura de Plotly
    """
    fig = go.Figure()
    
    # Agregar l√≠nea de predicciones horarias
    if hourly_predictions_df is not None and len(hourly_predictions_df) > 0:
        pred_dates = pd.to_datetime(hourly_predictions_df['fecha_hora'])
        pred_values = hourly_predictions_df['demanda_horaria']
        
        fig.add_trace(go.Scatter(
            x=pred_dates,
            y=pred_values,
            mode='lines',
            name='Predicci√≥n Horaria',
            line=dict(color='#ff7f0e', width=2),
            hovertemplate='<b>%{x|%Y-%m-%d %H:00}</b><br>Predicci√≥n: %{y:,.2f} MWh<extra></extra>'
        ))
    
    # Agregar l√≠nea de datos hist√≥ricos horarios
    if hourly_historical_df is not None and len(hourly_historical_df) > 0:
        hist_dates = pd.to_datetime(hourly_historical_df['fecha_hora'])
        hist_values = hourly_historical_df['demanda_horaria']
        
        fig.add_trace(go.Scatter(
            x=hist_dates,
            y=hist_values,
            mode='lines',
            name='Hist√≥rico Real Horario',
            line=dict(color='#1f77b4', width=2),
            hovertemplate='<b>%{x|%Y-%m-%d %H:00}</b><br>Real: %{y:,.2f} MWh<extra></extra>'
        ))
    
    # Configurar layout
    fig.update_layout(
        title=dict(
            text=title,
            font=dict(size=20, color='#1f77b4')
        ),
        xaxis=dict(
            title='Fecha y Hora',
            showgrid=True,
            gridcolor='lightgray'
        ),
        yaxis=dict(
            title='Demanda Horaria (MWh)',
            showgrid=True,
            gridcolor='lightgray'
        ),
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        height=500,
        template='plotly_white'
    )
    
    return fig


def convert_base_curves_to_hourly_dataframe(api_response: Dict[str, Any]) -> Optional[pd.DataFrame]:
    """
    Convierte la respuesta del endpoint base-curve a un DataFrame con datos horarios
    
    Args:
        api_response: Respuesta JSON de la API con formato {"curves": {"YYYY-MM-DD": [P1, P2, ..., P24]}}
    
    Returns:
        DataFrame con columnas: fecha_hora, demanda_horaria, tipo
    """
    if "error" in api_response:
        return None
    
    if "curves" not in api_response:
        return None
    
    curves = api_response["curves"]
    
    if not curves or len(curves) == 0:
        return None
    
    # Convertir diccionario de curvas a DataFrame horario
    rows = []
    for fecha_str, periodos in curves.items():
        fecha = pd.to_datetime(fecha_str)
        
        # Cada d√≠a tiene 24 per√≠odos (P1-P24)
        for periodo in range(1, 25):
            if periodo <= len(periodos):
                # Crear datetime con la hora correspondiente (periodo 1 = 00:00, periodo 2 = 01:00, etc.)
                hora = periodo - 1  # P1 = 0, P2 = 1, ..., P24 = 23
                fecha_hora = fecha.replace(hour=hora, minute=0, second=0)
                
                rows.append({
                    "fecha_hora": fecha_hora,
                    "demanda_horaria": periodos[periodo - 1],  # √çndice 0-based
                    "tipo": "curva_base",
                    "periodo": periodo
                })
    
    if len(rows) == 0:
        return None
    
    df = pd.DataFrame(rows)
    df = df.sort_values("fecha_hora")
    return df


def plot_base_curves_vs_historical(base_curves_df, historical_df, title="Curvas Base vs Hist√≥ricos"):
    """
    Crea gr√°fica comparando curvas base con datos hist√≥ricos horarios
    
    Args:
        base_curves_df: DataFrame con curvas base (debe tener 'fecha_hora' y 'demanda_horaria')
        historical_df: DataFrame con datos hist√≥ricos horarios (debe tener 'fecha_hora' y 'demanda_horaria')
        title: T√≠tulo de la gr√°fica
    
    Returns:
        Figura de Plotly
    """
    fig = go.Figure()
    
    # Agregar l√≠nea de curvas base
    if base_curves_df is not None and len(base_curves_df) > 0:
        base_dates = pd.to_datetime(base_curves_df['fecha_hora'])
        base_values = base_curves_df['demanda_horaria']
        
        fig.add_trace(go.Scatter(
            x=base_dates,
            y=base_values,
            mode='lines',
            name='Curva Base',
            line=dict(color='#2ca02c', width=2),
            hovertemplate='<b>%{x|%Y-%m-%d %H:00}</b><br>Curva Base: %{y:,.2f} MW<extra></extra>'
        ))
    
    # Agregar l√≠nea de datos hist√≥ricos horarios
    if historical_df is not None and len(historical_df) > 0:
        hist_dates = pd.to_datetime(historical_df['fecha_hora'])
        hist_values = historical_df['demanda_horaria']
        
        fig.add_trace(go.Scatter(
            x=hist_dates,
            y=hist_values,
            mode='lines',
            name='Hist√≥rico Real',
            line=dict(color='#1f77b4', width=2),
            hovertemplate='<b>%{x|%Y-%m-%d %H:00}</b><br>Real: %{y:,.2f} MW<extra></extra>'
        ))
    
    # Configurar layout
    fig.update_layout(
        title=dict(
            text=title,
            font=dict(size=20, color='#1f77b4')
        ),
        xaxis=dict(
            title='Fecha y Hora',
            showgrid=True,
            gridcolor='lightgray'
        ),
        yaxis=dict(
            title='Demanda Horaria (MW)',
            showgrid=True,
            gridcolor='lightgray'
        ),
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        height=500,
        template='plotly_white'
    )
    
    return fig


# ============================================================================
# INTERFAZ PRINCIPAL
# ============================================================================

def main():
    st.markdown('<h1 class="main-header">‚ö° Dashboard de Predicci√≥n - EPM</h1>', unsafe_allow_html=True)
    
    # Sidebar - Configuraci√≥n
    st.sidebar.header("‚öôÔ∏è Configuraci√≥n")
    
    # URL de la API
    api_url = st.sidebar.text_input(
        "URL de la API",
        value=DEFAULT_API_URL,
        help="URL base del servidor de la API (ej: http://localhost:8000)"
    )
    
    # Verificar conexi√≥n con la API
    api_available = check_api_health(api_url)
    if api_available:
        st.sidebar.success("‚úÖ API conectada")
    else:
        st.sidebar.error(f"‚ùå No se pudo conectar a la API en {api_url}")
        st.sidebar.info("üí° Aseg√∫rate de que el servidor de la API est√© corriendo")
    
    # Selecci√≥n de UCP
    ucp_options = ['Atlantico', 'Antioquia']
    selected_ucp = st.sidebar.selectbox(
        "Seleccionar Ciudad/UCP",
        options=ucp_options,
        index=0
    )
    
    # Fecha de fin de datos hist√≥ricos (end_date)
    st.sidebar.subheader("üìÖ Fechas")
    
    # Obtener √∫ltima fecha disponible en hist√≥rico
    df_historico_full = load_historical_data_for_comparison(selected_ucp)
    default_end_date = datetime.now().date() - timedelta(days=1)
    min_date = datetime(2015, 1, 1).date()
    max_date = datetime.now().date()
    
    if df_historico_full is not None and len(df_historico_full) > 0:
        max_historical_date = df_historico_full['FECHA'].max().date()
        min_historical_date = df_historico_full['FECHA'].min().date()
        
        if max_historical_date < default_end_date:
            default_end_date = max_historical_date
        
        if min_historical_date > min_date:
            min_date = min_historical_date
        if max_historical_date < max_date:
            max_date = max_historical_date
        
        st.sidebar.info(f"üìä Rango disponible: {min_historical_date.strftime('%Y-%m-%d')} a {max_historical_date.strftime('%Y-%m-%d')}")
    else:
        st.sidebar.warning("‚ö†Ô∏è No se encontraron datos hist√≥ricos")
    
    end_date = st.sidebar.date_input(
        "Fecha final de datos hist√≥ricos",
        value=default_end_date,
        min_value=min_date,
        max_value=max_date,
        help="√öltima fecha con datos hist√≥ricos a usar. Las predicciones comenzar√°n desde el d√≠a siguiente."
    )
    
    if df_historico_full is not None and len(df_historico_full) > 0:
        prediction_start_date = end_date + timedelta(days=1)
        st.sidebar.info(f"üîÆ Las predicciones comenzar√°n desde: {prediction_start_date.strftime('%Y-%m-%d')}")
    
    # N√∫mero de d√≠as a predecir
    n_days = st.sidebar.number_input(
        "N√∫mero de d√≠as a predecir",
        min_value=1,
        max_value=90,
        value=30,
        help="Cantidad de d√≠as futuros a predecir (m√°ximo 90)"
    )
    
    # Opci√≥n de force_retrain
    force_retrain = st.sidebar.checkbox(
        "Forzar reentrenamiento",
        value=False,
        help="Si est√° marcado, el modelo se reentrenar√° antes de generar predicciones"
    )
    
    # Offset scalar para ajustar predicciones
    st.sidebar.subheader("üîß Ajustes de Predicci√≥n")
    offset_scalar = st.sidebar.slider(
        "Offset Scalar",
        min_value=0.1,
        max_value=2.0,
        value=1.0,
        step=0.01,
        help="Escalar para ajustar todas las predicciones (1.0 = sin ajuste, 1.2 = +20%, 0.8 = -20%)"
    )
    
    # Mostrar informaci√≥n del offset
    if offset_scalar != 1.0:
        cambio_pct = (offset_scalar - 1.0) * 100
        if cambio_pct > 0:
            st.sidebar.info(f"üìà Aumento: +{cambio_pct:.1f}%")
        else:
            st.sidebar.info(f"üìâ Disminuci√≥n: {cambio_pct:.1f}%")
    
    # Botones de acci√≥n
    st.sidebar.markdown("---")
    
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        predict_button = st.button("üîÆ Predecir", type="primary", use_container_width=True)
    
    with col2:
        train_button = st.button("üîß Entrenar", use_container_width=True)
    
    # ========================================================================
    # PROCESAMIENTO DE ACCIONES
    # ========================================================================
    
    # Inicializar estado de sesi√≥n
    if 'predictions_df' not in st.session_state:
        st.session_state.predictions_df = None
    if 'api_response' not in st.session_state:
        st.session_state.api_response = None
    if 'last_ucp' not in st.session_state:
        st.session_state.last_ucp = None
    if 'last_n_days' not in st.session_state:
        st.session_state.last_n_days = None
    
    # Acci√≥n: Entrenar
    if train_button:
        if not api_available:
            st.error(f"‚ùå No se pudo conectar a la API. Verifica que el servidor est√© corriendo en {api_url}")
        else:
            st.info(f"üîß Iniciando entrenamiento para {selected_ucp}... Esto puede tardar varios minutos.")
            
            with st.spinner("Entrenando modelo (esto puede tardar 5-10 minutos)..."):
                response = call_retrain_api(api_url, selected_ucp)
            
            if "error" in response:
                st.error(f"‚ùå {response['error']}")
            else:
                st.success(f"‚úÖ {response.get('message', 'Modelo entrenado exitosamente')}")
                
                # Mostrar m√©tricas si est√°n disponibles
                if "metricas" in response and isinstance(response["metricas"], dict):
                    metrics = response["metricas"]
                    st.subheader("üìä M√©tricas del Modelo Entrenado")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if 'val_metrics' in metrics:
                            mape = metrics['val_metrics'].get('mape', 0)
                            st.metric("MAPE", f"{mape:.2f}%")
                    
                    with col2:
                        if 'val_metrics' in metrics:
                            rmape = metrics['val_metrics'].get('rmape', 0)
                            st.metric("rMAPE", f"{rmape:.4f}")
                    
                    with col3:
                        if 'val_metrics' in metrics:
                            r2 = metrics['val_metrics'].get('r2', 0)
                            st.metric("R¬≤", f"{r2:.4f}")
                    
                    # Mostrar m√©tricas completas en expander
                    with st.expander("üìÑ Ver m√©tricas completas"):
                        st.json(metrics)
                elif "datos_entrenamiento" in response:
                    st.info(f"üìä Datos de entrenamiento: {response['datos_entrenamiento']}")
                
                # Limpiar cache para que se recargue el modelo
                st.cache_data.clear()
                st.info("üí° El modelo ha sido actualizado. Puedes generar nuevas predicciones ahora.")
    
    # Acci√≥n: Predecir
    if predict_button:
        if not api_available:
            st.error(f"‚ùå No se pudo conectar a la API. Verifica que el servidor est√© corriendo en {api_url}")
        else:
            st.info(f"üîÆ Generando predicci√≥n para {selected_ucp}...")
            st.info(f"üìÖ Usando datos hist√≥ricos hasta: {end_date.strftime('%Y-%m-%d')}")
            
            with st.spinner(f"Prediciendo {n_days} d√≠as (esto puede tardar 1-2 minutos)..."):
                # Convertir end_date a string para la API
                end_date_str = end_date.strftime('%Y-%m-%d')
                
                # Mostrar informaci√≥n del offset si est√° aplicado
                if offset_scalar != 1.0:
                    cambio_pct = (offset_scalar - 1.0) * 100
                    if cambio_pct > 0:
                        st.info(f"üîß Aplicando offset: +{cambio_pct:.1f}% (scalar: {offset_scalar:.2f})")
                    else:
                        st.info(f"üîß Aplicando offset: {cambio_pct:.1f}% (scalar: {offset_scalar:.2f})")
                
                response = call_predict_api(
                    api_url=api_url,
                    ucp=selected_ucp,
                    n_days=n_days,
                    end_date=end_date_str,
                    force_retrain=force_retrain,
                    offset_scalar=offset_scalar if offset_scalar != 1.0 else None
                )
            
            if "error" in response:
                st.error(f"‚ùå Error en predicci√≥n: {response['error']}")
                st.session_state.predictions_df = None
                st.session_state.api_response = None
            else:
                st.success("‚úÖ Predicci√≥n generada exitosamente!")
                
                # Convertir respuesta a DataFrame
                predictions_df = convert_predictions_to_dataframe(response)
                
                if predictions_df is None or len(predictions_df) == 0:
                    st.warning("‚ö†Ô∏è No se recibieron predicciones en la respuesta de la API")
                    st.json(response)  # Mostrar respuesta completa para debugging
                else:
                    st.session_state.predictions_df = predictions_df
                    st.session_state.api_response = response
                    st.session_state.last_ucp = selected_ucp
                    st.session_state.last_n_days = n_days
    
    # ========================================================================
    # VISUALIZACI√ìN DE RESULTADOS
    # ========================================================================
    
    if st.session_state.predictions_df is not None:
        predictions_df = st.session_state.predictions_df
        api_response = st.session_state.api_response
        
        # Asegurar que la columna de fecha est√© en formato datetime
        if 'fecha' in predictions_df.columns:
            predictions_df['fecha'] = pd.to_datetime(predictions_df['fecha'])
        
        # Determinar columna de demanda
        if 'demanda_predicha' in predictions_df.columns:
            demanda_col = 'demanda_predicha'
        elif 'demanda_total' in predictions_df.columns:
            demanda_col = 'demanda_total'
        elif 'TOTAL' in predictions_df.columns:
            demanda_col = 'TOTAL'
        else:
            demanda_col = None
        
        if demanda_col is None:
            st.error("‚ùå No se encontr√≥ columna de demanda en las predicciones")
        else:
            # Calcular rango de fechas de predicciones
            fecha_inicio_pred = predictions_df['fecha'].min()
            fecha_fin_pred = predictions_df['fecha'].max()
            
            # Cargar datos hist√≥ricos para comparaci√≥n visual
            df_historico = load_historical_data_for_comparison(selected_ucp)
            
            # Extraer datos hist√≥ricos del rango de fechas de predicciones
            historical_df = pd.DataFrame()
            if df_historico is not None and len(df_historico) > 0:
                historical_df = get_historical_total(df_historico, fecha_inicio_pred, fecha_fin_pred)
            
            # Mostrar metadata de la API si est√° disponible
            if api_response and "metadata" in api_response:
                metadata = api_response["metadata"]
                st.markdown("---")
                st.subheader("üìä Informaci√≥n de la Predicci√≥n")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    if "fecha_inicio" in metadata:
                        st.metric("Fecha Inicio", metadata["fecha_inicio"])
                
                with col2:
                    if "fecha_fin" in metadata:
                        st.metric("Fecha Fin", metadata["fecha_fin"])
                
                with col3:
                    if "dias_predichos" in metadata:
                        st.metric("D√≠as Predichos", metadata["dias_predichos"])
                
                with col4:
                    if "modelo_entrenado" in metadata:
                        status = "‚úÖ S√≠" if metadata["modelo_entrenado"] else "‚ùå No"
                        st.metric("Modelo Entrenado", status)
                
                # Mostrar m√©tricas del modelo si est√°n disponibles
                if "metricas_modelo" in metadata:
                    st.markdown("---")
                    st.subheader("üìà M√©tricas del Modelo")
                    metrics = metadata["metricas_modelo"]
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if "mape" in metrics:
                            st.metric("MAPE", f"{metrics['mape']:.2f}%")
                    
                    with col2:
                        if "rmape" in metrics:
                            st.metric("rMAPE", f"{metrics['rmape']:.4f}")
                    
                    with col3:
                        if "r2" in metrics:
                            st.metric("R¬≤", f"{metrics['r2']:.4f}")
            
            # Mostrar m√©tricas principales de predicciones
            st.markdown("---")
            st.subheader("üìä M√©tricas de Predicci√≥n")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "Demanda Promedio",
                    f"{predictions_df[demanda_col].mean():,.0f} MWh"
                )
            
            with col2:
                st.metric(
                    "Demanda M√≠nima",
                    f"{predictions_df[demanda_col].min():,.0f} MWh"
                )
            
            with col3:
                st.metric(
                    "Demanda M√°xima",
                    f"{predictions_df[demanda_col].max():,.0f} MWh"
                )
            
            with col4:
                st.metric(
                    "Total D√≠as",
                    f"{len(predictions_df)}"
                )
            
            # Mostrar recomendaci√≥n de reentrenamiento si est√° disponible
            if api_response and "should_retrain" in api_response:
                st.markdown("---")
                if api_response["should_retrain"]:
                    st.warning(f"‚ö†Ô∏è **Recomendaci√≥n:** {api_response.get('reason', 'Se recomienda reentrenar el modelo')}")
                else:
                    st.success(f"‚úÖ {api_response.get('reason', 'El modelo est√° funcionando correctamente')}")
            
            # Mostrar eventos futuros si est√°n disponibles
            if api_response and "events" in api_response and api_response["events"]:
                st.markdown("---")
                st.subheader("üìÖ Eventos Futuros Relevantes")
                events = api_response["events"]
                for fecha, evento in events.items():
                    st.info(f"**{fecha}**: {evento}")
            
            # Gr√°fica principal
            st.markdown("---")
            st.subheader("üìà Predicciones vs Hist√≥ricos")
            
            # Preparar datos para gr√°fica
            pred_for_plot = pd.DataFrame({
                'fecha': predictions_df['fecha'],
                'demanda_total': predictions_df[demanda_col]
            })
            
            # Crear gr√°fica
            fig = plot_predictions_vs_historical(
                pred_for_plot,
                historical_df,
                title=f"Predicciones vs Hist√≥ricos - {selected_ucp}"
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ========================================================================
            # GR√ÅFICA HORARIA
            # ========================================================================
            st.markdown("---")
            st.subheader("‚è∞ Predicciones Horarias vs Hist√≥ricos")
            
            # Convertir predicciones a formato horario
            hourly_predictions_df = convert_predictions_to_hourly_dataframe(api_response)
            
            # Extraer datos hist√≥ricos horarios si est√°n disponibles
            hourly_historical_df = pd.DataFrame()
            if df_historico is not None and len(df_historico) > 0:
                hourly_historical_df = get_historical_hourly_data(df_historico, fecha_inicio_pred, fecha_fin_pred)
            
            # Crear gr√°fica horaria
            if hourly_predictions_df is not None and len(hourly_predictions_df) > 0:
                fig_hourly = plot_hourly_predictions_vs_historical(
                    hourly_predictions_df,
                    hourly_historical_df,
                    title=f"Predicciones Horarias vs Hist√≥ricos - {selected_ucp}"
                )
                st.plotly_chart(fig_hourly, use_container_width=True)
                
                # Mostrar informaci√≥n sobre los datos horarios
                if len(hourly_historical_df) > 0:
                    st.info(f"üìä Mostrando {len(hourly_predictions_df)} horas de predicciones y {len(hourly_historical_df)} horas de datos hist√≥ricos")
                else:
                    st.info(f"üìä Mostrando {len(hourly_predictions_df)} horas de predicciones (no hay datos hist√≥ricos horarios disponibles para este per√≠odo)")
            else:
                st.warning("‚ö†Ô∏è No se pudieron extraer datos horarios de las predicciones")
            
            # Mostrar tabla de comparaci√≥n si hay datos hist√≥ricos
            if len(historical_df) > 0:
                st.markdown("---")
                st.subheader("üìã Comparaci√≥n Detallada")
                
                # Unir predicciones con hist√≥ricos
                comparison_df = pred_for_plot.copy()
                comparison_df = comparison_df.merge(
                    historical_df[['fecha', 'demanda_total']],
                    on='fecha',
                    how='left',
                    suffixes=('_pred', '_real')
                )
                
                # Calcular errores
                comparison_df['error_abs'] = (
                    comparison_df['demanda_total_pred'] - comparison_df['demanda_total_real']
                ).abs()
                comparison_df['error_pct'] = (
                    (comparison_df['error_abs'] / comparison_df['demanda_total_real']) * 100
                ).round(2)
                
                # Renombrar columnas para visualizaci√≥n
                comparison_df = comparison_df.rename(columns={
                    'fecha': 'Fecha',
                    'demanda_total_pred': 'Predicci√≥n (MWh)',
                    'demanda_total_real': 'Real (MWh)',
                    'error_abs': 'Error Absoluto (MWh)',
                    'error_pct': 'Error (%)'
                })
                
                # Mostrar tabla
                st.dataframe(
                    comparison_df,
                    use_container_width=True,
                    hide_index=True
                )
                
                # M√©tricas de error
                if comparison_df['Error (%)'].notna().any():
                    avg_error = comparison_df['Error (%)'].mean()
                    max_error = comparison_df['Error (%)'].max()
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Error Promedio (%)", f"{avg_error:.2f}%")
                    with col2:
                        st.metric("Error M√°ximo (%)", f"{max_error:.2f}%")
            
            # Mostrar datos completos en expander
            with st.expander("üìÑ Ver datos completos de predicci√≥n"):
                st.dataframe(predictions_df, use_container_width=True)
            
            # Mostrar respuesta completa de la API en expander (para debugging)
            with st.expander("üîç Ver respuesta completa de la API"):
                st.json(api_response)
    
    else:
        # Mensaje inicial
        st.info("üëà Configura los par√°metros en la barra lateral y haz clic en 'üîÆ Predecir' para generar una predicci√≥n")
        
        # Mostrar informaci√≥n del sistema
        st.markdown("---")
        st.subheader("‚ÑπÔ∏è Informaci√≥n del Sistema")
        
        if api_available:
            st.success("‚úÖ API conectada y disponible")
        else:
            st.error(f"‚ùå No se pudo conectar a la API en {api_url}")
            st.info("üí° Para iniciar la API, ejecuta: `uvicorn src.api.main:app --reload`")
    
    # ========================================================================
    # SECCI√ìN: CURVAS BASE
    # ========================================================================
    st.markdown("---")
    st.markdown("---")
    st.subheader("üìä Curvas Base de Demanda")
    st.markdown("Obt√©n curvas base de demanda horaria para un rango de fechas espec√≠fico")
    
    # Formulario para curvas base
    col1, col2, col3 = st.columns(3)
    
    with col1:
        base_curve_ucp = st.selectbox(
            "UCP para Curva Base",
            options=ucp_options,
            index=0,
            key="base_curve_ucp"
        )
    
    with col2:
        base_curve_fecha_inicio = st.date_input(
            "Fecha Inicio",
            value=datetime.now().date(),
            key="base_curve_fecha_inicio"
        )
    
    with col3:
        base_curve_fecha_fin = st.date_input(
            "Fecha Fin",
            value=datetime.now().date() + timedelta(days=30),
            key="base_curve_fecha_fin"
        )
    
    base_curve_button = st.button("üìä Obtener Curvas Base", type="primary", use_container_width=True)
    
    # Inicializar estado de sesi√≥n para curvas base
    if 'base_curves_df' not in st.session_state:
        st.session_state.base_curves_df = None
    if 'base_curves_response' not in st.session_state:
        st.session_state.base_curves_response = None
    if 'base_curves_historical_df' not in st.session_state:
        st.session_state.base_curves_historical_df = None
    
    # Procesar solicitud de curvas base
    if base_curve_button:
        if not api_available:
            st.error(f"‚ùå No se pudo conectar a la API. Verifica que el servidor est√© corriendo en {api_url}")
        else:
            if base_curve_fecha_inicio > base_curve_fecha_fin:
                st.error("‚ùå La fecha de inicio debe ser anterior o igual a la fecha de fin")
            else:
                st.info(f"üìä Obteniendo curvas base para {base_curve_ucp} desde {base_curve_fecha_inicio} hasta {base_curve_fecha_fin}...")
                
                with st.spinner("Consultando endpoint de curvas base..."):
                    fecha_inicio_str = base_curve_fecha_inicio.strftime('%Y-%m-%d')
                    fecha_fin_str = base_curve_fecha_fin.strftime('%Y-%m-%d')
                    
                    response = call_base_curve_api(
                        api_url=api_url,
                        ucp=base_curve_ucp,
                        fecha_inicio=fecha_inicio_str,
                        fecha_fin=fecha_fin_str
                    )
                
                if "error" in response:
                    st.error(f"‚ùå Error obteniendo curvas base: {response['error']}")
                    st.session_state.base_curves_df = None
                    st.session_state.base_curves_response = None
                else:
                    st.success("‚úÖ Curvas base obtenidas exitosamente!")
                    
                    # Convertir respuesta a DataFrame
                    base_curves_df = convert_base_curves_to_hourly_dataframe(response)
                    
                    if base_curves_df is None or len(base_curves_df) == 0:
                        st.warning("‚ö†Ô∏è No se recibieron curvas base en la respuesta de la API")
                        st.json(response)  # Mostrar respuesta completa para debugging
                    else:
                        st.session_state.base_curves_df = base_curves_df
                        st.session_state.base_curves_response = response
                        
                        # Intentar cargar datos hist√≥ricos para comparaci√≥n
                        df_historico = load_historical_data_for_comparison(base_curve_ucp)
                        if df_historico is not None and len(df_historico) > 0:
                            fecha_inicio_dt = pd.to_datetime(base_curve_fecha_inicio)
                            fecha_fin_dt = pd.to_datetime(base_curve_fecha_fin)
                            historical_df = get_historical_hourly_data(df_historico, fecha_inicio_dt, fecha_fin_dt)
                            st.session_state.base_curves_historical_df = historical_df
                        else:
                            st.session_state.base_curves_historical_df = pd.DataFrame()
    
    # Mostrar gr√°fica de curvas base si hay datos
    if st.session_state.base_curves_df is not None and len(st.session_state.base_curves_df) > 0:
        base_curves_df = st.session_state.base_curves_df
        historical_df = st.session_state.base_curves_historical_df if st.session_state.base_curves_historical_df is not None else pd.DataFrame()
        
        # Calcular estad√≠sticas
        st.markdown("---")
        st.subheader("üìà Visualizaci√≥n de Curvas Base")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Demanda Promedio",
                f"{base_curves_df['demanda_horaria'].mean():,.0f} MW"
            )
        
        with col2:
            st.metric(
                "Demanda M√≠nima",
                f"{base_curves_df['demanda_horaria'].min():,.0f} MW"
            )
        
        with col3:
            st.metric(
                "Demanda M√°xima",
                f"{base_curves_df['demanda_horaria'].max():,.0f} MW"
            )
        
        with col4:
            total_horas = len(base_curves_df)
            total_dias = len(set(base_curves_df['fecha_hora'].dt.date))
            st.metric(
                "Total Horas",
                f"{total_horas} ({total_dias} d√≠as)"
            )
        
        # Crear gr√°fica
        fig_base = plot_base_curves_vs_historical(
            base_curves_df,
            historical_df,
            title=f"Curvas Base vs Hist√≥ricos - {base_curve_ucp}"
        )
        
        st.plotly_chart(fig_base, use_container_width=True)
        
        # Informaci√≥n sobre datos hist√≥ricos
        if historical_df is not None and len(historical_df) > 0:
            st.info(f"üìä Mostrando {len(base_curves_df)} horas de curvas base y {len(historical_df)} horas de datos hist√≥ricos")
            
            # Mostrar tabla de comparaci√≥n si hay datos hist√≥ricos
            st.markdown("---")
            st.subheader("üìã Comparaci√≥n Detallada")
            
            # Unir curvas base con hist√≥ricos
            comparison_df = base_curves_df[['fecha_hora', 'demanda_horaria']].copy()
            comparison_df = comparison_df.rename(columns={'demanda_horaria': 'curva_base'})
            
            comparison_df = comparison_df.merge(
                historical_df[['fecha_hora', 'demanda_horaria']],
                on='fecha_hora',
                how='left',
                suffixes=('', '_real')
            )
            comparison_df = comparison_df.rename(columns={'demanda_horaria': 'historico_real'})
            
            # Calcular errores
            comparison_df['error_abs'] = (
                comparison_df['curva_base'] - comparison_df['historico_real']
            ).abs()
            comparison_df['error_pct'] = (
                (comparison_df['error_abs'] / comparison_df['historico_real']) * 100
            ).round(2)
            
            # Renombrar columnas para visualizaci√≥n
            comparison_df = comparison_df.rename(columns={
                'fecha_hora': 'Fecha y Hora',
                'curva_base': 'Curva Base (MW)',
                'historico_real': 'Hist√≥rico Real (MW)',
                'error_abs': 'Error Absoluto (MW)',
                'error_pct': 'Error (%)'
            })
            
            # Mostrar tabla
            st.dataframe(
                comparison_df,
                use_container_width=True,
                hide_index=True
            )
            
            # M√©tricas de error
            if comparison_df['Error (%)'].notna().any():
                avg_error = comparison_df['Error (%)'].mean()
                max_error = comparison_df['Error (%)'].max()
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Error Promedio (%)", f"{avg_error:.2f}%")
                with col2:
                    st.metric("Error M√°ximo (%)", f"{max_error:.2f}%")
        else:
            st.info(f"üìä Mostrando {len(base_curves_df)} horas de curvas base (no hay datos hist√≥ricos disponibles para este per√≠odo)")
        
        # Mostrar datos completos en expander
        with st.expander("üìÑ Ver datos completos de curvas base"):
            st.dataframe(base_curves_df, use_container_width=True)
        
        # Mostrar respuesta completa de la API en expander (para debugging)
        with st.expander("üîç Ver respuesta completa de la API"):
            st.json(st.session_state.base_curves_response)


if __name__ == "__main__":
    main()
