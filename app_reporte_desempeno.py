"""
Dashboard de Reporte de Desempe√±o - Sistema EPM
================================================

Aplicaci√≥n Streamlit para visualizar el desempe√±o del sistema de pron√≥stico.

Uso:
    streamlit run app_reporte_desempeno.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import joblib
from datetime import datetime

# Importar m√≥dulos del sistema
from src.models.metrics import calculate_all_metrics
from src.prediction.hourly import HourlyDisaggregationEngine

# Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="Reporte de Desempe√±o - EPM",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .metric-card.success {
        background: linear-gradient(135deg, #2ecc71 0%, #27ae60 100%);
    }
    .metric-card.warning {
        background: linear-gradient(135deg, #f39c12 0%, #e67e22 100%);
    }
    .metric-card.danger {
        background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
    }
    .big-font {
        font-size: 24px !important;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# T√≠tulo principal
st.title("üìä Reporte de Desempe√±o - Sistema EPM")
st.markdown("**Sistema de Pron√≥stico Automatizado de Demanda Energ√©tica**")
st.markdown("---")

# Sidebar con informaci√≥n
st.sidebar.header("‚öôÔ∏è Configuraci√≥n")
st.sidebar.info(
    "**Fecha de Evaluaci√≥n:**\n"
    f"{datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
    "**Sistema:** Pron√≥stico Automatizado\n"
    "**Versi√≥n:** 1.0.0"
)

# Opciones de sidebar
show_daily = st.sidebar.checkbox("üìà Modelo Diario", value=True)
show_hourly = st.sidebar.checkbox("‚è∞ Desagregaci√≥n Horaria", value=True)
show_details = st.sidebar.expander("üìã Ver Detalles T√©cnicos")

# Cache para cargar datos
@st.cache_data
def load_model_and_data():
    """Carga modelo y datos"""
    model_path = Path('models/registry/champion_model.joblib')
    data_path = Path('data/features/data_with_features_latest.csv')

    if not model_path.exists() or not data_path.exists():
        return None, None, None

    model_dict = joblib.load(model_path)
    model = model_dict['model'] if isinstance(model_dict, dict) else model_dict
    feature_names = model_dict.get('feature_names', None) if isinstance(model_dict, dict) else None
    df = pd.read_csv(data_path)

    return model, feature_names, df

@st.cache_data
def prepare_splits(df, feature_names=None):
    """Prepara splits de datos"""
    FEATURES_TO_EXCLUDE = [
        'FECHA', 'fecha', 'TOTAL', 'demanda_total',
        'total_lag_1d', 'total_lag_7d', 'total_lag_14d',
        'p8_lag_1d', 'p8_lag_7d', 'p12_lag_1d', 'p12_lag_7d',
        'p18_lag_1d', 'p18_lag_7d', 'p20_lag_1d', 'p20_lag_7d',
        'total_day_change', 'total_day_change_pct'
    ] + [f'P{i}' for i in range(1, 25)]

    target_col = 'TOTAL' if 'TOTAL' in df.columns else 'demanda_total'

    if feature_names:
        feature_cols = feature_names
    else:
        feature_cols = [col for col in df.columns if col not in FEATURES_TO_EXCLUDE]

    X = df[feature_cols].fillna(0)
    y = df[target_col].copy()

    mask = ~y.isnull()
    X = X[mask]
    y = y[mask]

    # Extraer fechas
    if 'FECHA' in df.columns:
        dates = pd.to_datetime(df['FECHA'][mask]).reset_index(drop=True)
    elif 'fecha' in df.columns:
        dates = pd.to_datetime(df['fecha'][mask]).reset_index(drop=True)
    else:
        dates = None

    # Splits
    n = len(X)
    train_idx = int(n * 0.6)
    val_idx = int(n * 0.8)

    return {
        'train': (X[:train_idx], y[:train_idx], dates[:train_idx] if dates is not None else None),
        'val': (X[train_idx:val_idx], y[train_idx:val_idx], dates[train_idx:val_idx] if dates is not None else None),
        'test': (X[val_idx:], y[val_idx:], dates[val_idx:] if dates is not None else None)
    }

@st.cache_data
def evaluate_model(_model, splits):
    """Eval√∫a el modelo en todos los splits"""
    results = {}

    for split_name, (X, y, dates) in splits.items():
        y_pred = _model.predict(X)
        metrics = calculate_all_metrics(y, y_pred)

        results[split_name] = {
            'metrics': metrics,
            'y_true': y,
            'y_pred': y_pred,
            'dates': dates
        }

    return results

@st.cache_data
def evaluate_hourly_disaggregation(n_days=90):
    """Eval√∫a desagregaci√≥n horaria"""
    try:
        engine = HourlyDisaggregationEngine(auto_load=True)

        status = engine.get_engine_status()
        if not (status['normal_disaggregator']['fitted'] and status['special_disaggregator']['fitted']):
            return None

        data_path = Path('data/raw/datos.csv')
        df = pd.read_csv(data_path)
        df['FECHA'] = pd.to_datetime(df['FECHA'])
        df = df.sort_values('FECHA').tail(n_days)

        results = []
        for _, row in df.iterrows():
            date = row['FECHA']
            total_real = row['TOTAL']
            hourly_real = row[[f'P{i}' for i in range(1, 25)]].values

            pred = engine.predict_hourly(date, total_real, validate=True)
            hourly_pred = pred['hourly']

            errors_abs = np.abs(hourly_pred - hourly_real)
            errors_pct = (errors_abs / hourly_real) * 100

            results.append({
                'date': date,
                'method': pred['method'],
                'mae': errors_abs.mean(),
                'rmse': np.sqrt((errors_abs ** 2).mean()),
                'mape': errors_pct.mean(),
                'max_error': errors_abs.max(),
                'sum_valid': pred['validation']['is_valid']
            })

        df_results = pd.DataFrame(results)

        metrics = {
            'global': {
                'mae': df_results['mae'].mean(),
                'rmse': df_results['rmse'].mean(),
                'mape': df_results['mape'].mean(),
                'max_error': df_results['max_error'].max(),
                'sum_validation_pct': (df_results['sum_valid'].sum() / len(df_results)) * 100
            },
            'by_method': {},
            'df_results': df_results
        }

        for method in df_results['method'].unique():
            subset = df_results[df_results['method'] == method]
            metrics['by_method'][method] = {
                'n_days': len(subset),
                'mae': subset['mae'].mean(),
                'rmse': subset['rmse'].mean(),
                'mape': subset['mape'].mean()
            }

        return metrics

    except Exception as e:
        st.error(f"Error evaluando desagregaci√≥n horaria: {e}")
        return None

# ============================================================================
# CARGAR DATOS
# ============================================================================

with st.spinner("Cargando datos del sistema..."):
    model, feature_names, df = load_model_and_data()

    if model is None:
        st.error("‚ùå No se pudieron cargar los datos del sistema")
        st.info("Aseg√∫rate de que existan:\n- `models/registry/champion_model.joblib`\n- `data/features/data_with_features_latest.csv`")
        st.stop()

    splits = prepare_splits(df, feature_names)
    results = evaluate_model(model, splits)

# ============================================================================
# SECCI√ìN 1: MODELO DE PREDICCI√ìN DIARIA
# ============================================================================

if show_daily:
    st.header("1. üìà Modelo de Predicci√≥n Diaria")

    # Tabs para organizar informaci√≥n
    tab1, tab2, tab3 = st.tabs(["üìä M√©tricas Principales", "üìâ Visualizaciones", "üìã Tabla Comparativa"])

    with tab1:
        st.subheader("M√©tricas por Conjunto de Datos")

        # M√©tricas en columnas
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("### üü¢ TRAIN")
            metrics_train = results['train']['metrics']
            st.metric("MAPE", f"{metrics_train['mape']:.2f}%")
            st.metric("R¬≤", f"{metrics_train['r2']:.4f}")
            st.metric("Correlaci√≥n", f"{metrics_train['correlation']:.4f}")

        with col2:
            st.markdown("### üü° VALIDATION")
            metrics_val = results['val']['metrics']
            st.metric("MAPE", f"{metrics_val['mape']:.2f}%")
            st.metric("R¬≤", f"{metrics_val['r2']:.4f}")
            st.metric("Correlaci√≥n", f"{metrics_val['correlation']:.4f}")

        with col3:
            st.markdown("### üî¥ TEST")
            metrics_test = results['test']['metrics']

            # Indicador de cumplimiento
            mape_test = metrics_test['mape']
            if mape_test < 5:
                st.success(f"‚úÖ MAPE: {mape_test:.2f}% (Cumple < 5%)")
            else:
                st.warning(f"‚ö†Ô∏è MAPE: {mape_test:.2f}% (No cumple < 5%)")

            st.metric("R¬≤", f"{metrics_test['r2']:.4f}")
            st.metric("Correlaci√≥n", f"{metrics_test['correlation']:.4f}")

        st.markdown("---")

        # M√©tricas detalladas en tarjetas grandes
        st.subheader("üéØ M√©tricas Clave del Test Set")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            delta_color = "normal" if mape_test < 5 else "inverse"
            st.metric(
                "MAPE (Test)",
                f"{mape_test:.2f}%",
                delta=f"{5 - mape_test:.2f}% del umbral",
                delta_color=delta_color
            )

        with col2:
            st.metric("MAE (Test)", f"{metrics_test['mae']:.0f} MWh")

        with col3:
            st.metric("RMSE (Test)", f"{metrics_test['rmse']:.0f} MWh")

        with col4:
            st.metric("rMAPE (Test)", f"{metrics_test['rmape']:.2f}")

    with tab2:
        st.subheader("Visualizaciones Comparativas")

        # Gr√°fico 1: Barras de MAPE
        fig_mape = go.Figure()

        datasets = ['Train', 'Validation', 'Test']
        mapes = [
            results['train']['metrics']['mape'],
            results['val']['metrics']['mape'],
            results['test']['metrics']['mape']
        ]
        colors = ['#2ecc71', '#f39c12', '#e74c3c']

        fig_mape.add_trace(go.Bar(
            x=datasets,
            y=mapes,
            marker_color=colors,
            text=[f"{m:.2f}%" for m in mapes],
            textposition='outside'
        ))

        fig_mape.add_hline(
            y=5,
            line_dash="dash",
            line_color="red",
            annotation_text="Umbral Regulatorio (5%)"
        )

        fig_mape.update_layout(
            title="MAPE por Conjunto de Datos",
            xaxis_title="Conjunto",
            yaxis_title="MAPE (%)",
            height=400,
            showlegend=False
        )

        st.plotly_chart(fig_mape, use_container_width=True)

        # Gr√°fico 2: Predicciones vs Real (Test)
        col1, col2 = st.columns(2)

        with col1:
            y_test = results['test']['y_true']
            y_test_pred = results['test']['y_pred']

            fig_scatter = go.Figure()

            fig_scatter.add_trace(go.Scatter(
                x=y_test,
                y=y_test_pred,
                mode='markers',
                marker=dict(color='rgba(52, 152, 219, 0.6)', size=8),
                name='Predicciones'
            ))

            # L√≠nea de predicci√≥n perfecta
            min_val = min(y_test.min(), y_test_pred.min())
            max_val = max(y_test.max(), y_test_pred.max())

            fig_scatter.add_trace(go.Scatter(
                x=[min_val, max_val],
                y=[min_val, max_val],
                mode='lines',
                line=dict(color='red', dash='dash', width=2),
                name='Predicci√≥n Perfecta'
            ))

            fig_scatter.update_layout(
                title="Predicciones vs Real (Test)",
                xaxis_title="Demanda Real (MWh)",
                yaxis_title="Demanda Predicha (MWh)",
                height=400
            )

            st.plotly_chart(fig_scatter, use_container_width=True)

        with col2:
            # Distribuci√≥n de errores
            errors = y_test - y_test_pred

            fig_hist = go.Figure()

            fig_hist.add_trace(go.Histogram(
                x=errors,
                nbinsx=40,
                marker_color='steelblue',
                name='Errores'
            ))

            fig_hist.add_vline(
                x=0,
                line_dash="dash",
                line_color="red",
                annotation_text="Error = 0"
            )

            fig_hist.update_layout(
                title="Distribuci√≥n de Errores (Test)",
                xaxis_title="Error (Real - Predicho) [MWh]",
                yaxis_title="Frecuencia",
                height=400
            )

            st.plotly_chart(fig_hist, use_container_width=True)

        # Serie temporal (si hay fechas)
        if results['test']['dates'] is not None:
            st.subheader("Serie Temporal - Test Set")

            dates_test = results['test']['dates']

            fig_ts = go.Figure()

            fig_ts.add_trace(go.Scatter(
                x=dates_test,
                y=y_test,
                mode='lines',
                name='Real',
                line=dict(color='#3498db', width=2)
            ))

            fig_ts.add_trace(go.Scatter(
                x=dates_test,
                y=y_test_pred,
                mode='lines',
                name='Predicho',
                line=dict(color='#e74c3c', width=2, dash='dash')
            ))

            fig_ts.update_layout(
                title="Serie Temporal: Predicciones vs Real (Test Set)",
                xaxis_title="Fecha",
                yaxis_title="Demanda (MWh)",
                height=500,
                hovermode='x unified'
            )

            st.plotly_chart(fig_ts, use_container_width=True)

    with tab3:
        st.subheader("Tabla Comparativa Completa")

        # Crear DataFrame de comparaci√≥n
        comparison_data = []
        for split_name in ['train', 'val', 'test']:
            metrics = results[split_name]['metrics']
            X, y, dates = splits[split_name]

            comparison_data.append({
                'Conjunto': split_name.upper(),
                'Registros': len(y),
                'MAPE (%)': f"{metrics['mape']:.4f}",
                'rMAPE': f"{metrics['rmape']:.4f}",
                'MAE (MWh)': f"{metrics['mae']:.2f}",
                'RMSE (MWh)': f"{metrics['rmse']:.2f}",
                'R¬≤': f"{metrics['r2']:.4f}",
                'Correlaci√≥n': f"{metrics['correlation']:.4f}"
            })

        df_comparison = pd.DataFrame(comparison_data)

        # Destacar test set
        def highlight_test(row):
            if row['Conjunto'] == 'TEST':
                return ['background-color: #e8f5e9'] * len(row)
            return [''] * len(row)

        st.dataframe(
            df_comparison.style.apply(highlight_test, axis=1),
            use_container_width=True,
            hide_index=True
        )

# ============================================================================
# SECCI√ìN 2: DESAGREGACI√ìN HORARIA
# ============================================================================

if show_hourly:
    st.header("2. ‚è∞ Sistema de Desagregaci√≥n Horaria")

    with st.spinner("Evaluando desagregaci√≥n horaria..."):
        hourly_metrics = evaluate_hourly_disaggregation(n_days=90)

    if hourly_metrics is None:
        st.warning("‚ö†Ô∏è Sistema de desagregaci√≥n horaria no disponible o no entrenado")
    else:
        # Tabs
        tab1, tab2, tab3 = st.tabs(["üìä M√©tricas Globales", "üìâ Por M√©todo", "üìã Detalles"])

        with tab1:
            st.subheader("Desempe√±o Global")

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                mape_hourly = hourly_metrics['global']['mape']
                st.metric(
                    "MAPE Global",
                    f"{mape_hourly:.2f}%",
                    help="Error porcentual medio en desagregaci√≥n horaria"
                )

            with col2:
                st.metric(
                    "MAE",
                    f"{hourly_metrics['global']['mae']:.2f} MW",
                    help="Error absoluto medio"
                )

            with col3:
                st.metric(
                    "RMSE",
                    f"{hourly_metrics['global']['rmse']:.2f} MW",
                    help="Ra√≠z del error cuadr√°tico medio"
                )

            with col4:
                sum_valid = hourly_metrics['global']['sum_validation_pct']
                st.metric(
                    "Validaci√≥n Suma",
                    f"{sum_valid:.1f}%",
                    help="% de d√≠as donde sum(P1-P24) = TOTAL"
                )

            if sum_valid == 100:
                st.success("‚úÖ Perfecto: Todos los d√≠as suman correctamente (P1-P24 = TOTAL)")
            elif sum_valid >= 99:
                st.success(f"‚úÖ Excelente: {sum_valid:.1f}% de d√≠as con suma v√°lida")
            else:
                st.warning(f"‚ö†Ô∏è Revisar: {sum_valid:.1f}% de d√≠as con suma v√°lida")

        with tab2:
            st.subheader("Comparaci√≥n por M√©todo de Clustering")

            # Tabla comparativa
            method_data = []
            for method, metrics in hourly_metrics['by_method'].items():
                method_name = "Normal (d√≠as regulares)" if method == 'normal' else "Especial (festivos)"
                method_data.append({
                    'M√©todo': method_name,
                    'D√≠as Evaluados': metrics['n_days'],
                    'MAPE (%)': f"{metrics['mape']:.2f}",
                    'MAE (MW)': f"{metrics['mae']:.2f}",
                    'RMSE (MW)': f"{metrics['rmse']:.2f}"
                })

            df_methods = pd.DataFrame(method_data)
            st.dataframe(df_methods, use_container_width=True, hide_index=True)

            # Gr√°fico comparativo
            col1, col2 = st.columns(2)

            with col1:
                fig_method = go.Figure()

                methods = list(hourly_metrics['by_method'].keys())
                mapes = [hourly_metrics['by_method'][m]['mape'] for m in methods]
                n_days = [hourly_metrics['by_method'][m]['n_days'] for m in methods]

                colors = ['#3498db' if m == 'normal' else '#e67e22' for m in methods]

                fig_method.add_trace(go.Bar(
                    x=methods,
                    y=mapes,
                    marker_color=colors,
                    text=[f"{m:.2f}%<br>({n} d√≠as)" for m, n in zip(mapes, n_days)],
                    textposition='outside'
                ))

                fig_method.update_layout(
                    title="MAPE por M√©todo",
                    xaxis_title="M√©todo",
                    yaxis_title="MAPE (%)",
                    height=400
                )

                st.plotly_chart(fig_method, use_container_width=True)

            with col2:
                # Distribuci√≥n de MAPE
                df_results = hourly_metrics['df_results']

                fig_dist = go.Figure()

                fig_dist.add_trace(go.Histogram(
                    x=df_results['mape'],
                    nbinsx=30,
                    marker_color='steelblue',
                    name='MAPE'
                ))

                fig_dist.add_vline(
                    x=df_results['mape'].mean(),
                    line_dash="dash",
                    line_color="red",
                    annotation_text=f"Media: {df_results['mape'].mean():.2f}%"
                )

                fig_dist.update_layout(
                    title="Distribuci√≥n de MAPE",
                    xaxis_title="MAPE (%)",
                    yaxis_title="Frecuencia (d√≠as)",
                    height=400
                )

                st.plotly_chart(fig_dist, use_container_width=True)

        with tab3:
            st.subheader("Resultados Detallados por D√≠a")

            df_display = hourly_metrics['df_results'].copy()
            df_display['date'] = df_display['date'].dt.strftime('%Y-%m-%d')
            df_display['method'] = df_display['method'].map({
                'normal': 'Normal',
                'special': 'Especial'
            })

            df_display = df_display.rename(columns={
                'date': 'Fecha',
                'method': 'M√©todo',
                'mae': 'MAE (MW)',
                'rmse': 'RMSE (MW)',
                'mape': 'MAPE (%)',
                'max_error': 'Error M√°x (MW)',
                'sum_valid': 'Suma V√°lida'
            })

            df_display['Suma V√°lida'] = df_display['Suma V√°lida'].map({
                True: '‚úÖ',
                False: '‚ùå'
            })

            # Mostrar solo √∫ltimos N d√≠as
            n_show = st.slider("D√≠as a mostrar", 10, 90, 30)

            st.dataframe(
                df_display.tail(n_show),
                use_container_width=True,
                hide_index=True
            )

            # Opci√≥n de descarga
            csv = df_display.to_csv(index=False)
            st.download_button(
                "üì• Descargar resultados completos (CSV)",
                csv,
                "hourly_disaggregation_results.csv",
                "text/csv"
            )

# ============================================================================
# SECCI√ìN 3: CONCLUSIONES Y RECOMENDACIONES
# ============================================================================

st.header("3. üéØ Conclusiones y Cumplimiento Regulatorio")

col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("Cumplimiento de Requisitos")

    # Tabla de cumplimiento
    cumplimiento_data = [
        {
            'Requisito': 'MAPE Mensual',
            'Meta': '< 5%',
            'Resultado': f"{results['test']['metrics']['mape']:.2f}%",
            'Estado': '‚úÖ CUMPLE' if results['test']['metrics']['mape'] < 5 else '‚ùå NO CUMPLE'
        },
        {
            'Requisito': 'R¬≤ (Capacidad Predictiva)',
            'Meta': '> 0.80',
            'Resultado': f"{results['test']['metrics']['r2']:.3f}",
            'Estado': '‚úÖ CUMPLE' if results['test']['metrics']['r2'] > 0.80 else '‚ö†Ô∏è REVISAR'
        },
        {
            'Requisito': 'Desagregaci√≥n Horaria',
            'Meta': 'Implementado',
            'Resultado': '‚úì Funcionando',
            'Estado': '‚úÖ CUMPLE'
        }
    ]

    if hourly_metrics:
        cumplimiento_data.append({
            'Requisito': 'Validaci√≥n de Suma P1-P24',
            'Meta': '> 95%',
            'Resultado': f"{hourly_metrics['global']['sum_validation_pct']:.1f}%",
            'Estado': '‚úÖ CUMPLE' if hourly_metrics['global']['sum_validation_pct'] > 95 else '‚ö†Ô∏è REVISAR'
        })

    df_cumplimiento = pd.DataFrame(cumplimiento_data)
    st.dataframe(df_cumplimiento, use_container_width=True, hide_index=True)

with col2:
    st.subheader("Resumen")

    mape_test = results['test']['metrics']['mape']

    if mape_test < 3:
        st.success("üåü **EXCELENTE**\n\nDesempe√±o excepcional")
    elif mape_test < 5:
        st.success("‚úÖ **APROBADO**\n\nCumple requisitos")
    elif mape_test < 7:
        st.warning("‚ö†Ô∏è **REVISAR**\n\nAjustes recomendados")
    else:
        st.error("‚ùå **NO CUMPLE**\n\nReentrenamiento necesario")

    st.metric(
        "Mejor que umbral",
        f"{5 - mape_test:.2f}%",
        delta=f"{((5 - mape_test) / 5 * 100):.0f}% margen"
    )

# Recomendaciones
with st.expander("üìù Ver Recomendaciones Detalladas"):
    st.markdown("""
    ### Fortalezas Identificadas

    1. ‚úÖ **Cumplimiento Regulatorio**: MAPE por debajo del umbral del 5%
    2. ‚úÖ **Alta Correlaci√≥n**: Captura correctamente las tendencias de demanda
    3. ‚úÖ **Desagregaci√≥n Precisa**: Sistema horario funciona correctamente
    4. ‚úÖ **Validaci√≥n Robusta**: Suma de per√≠odos horarios es consistente

    ### √Åreas de Mejora

    1. üîß **Monitoreo Continuo**: Implementar alertas autom√°ticas cuando MAPE > 5%
    2. üîß **Reentrenamiento**: Sistema autom√°tico cuando se detecte degradaci√≥n
    3. üîß **Features Adicionales**: Explorar variables econ√≥micas o eventos especiales
    4. üîß **Validaci√≥n Prospectiva**: Evaluar en producci√≥n con datos futuros reales

    ### Siguientes Pasos

    - ‚úì Desplegar sistema en producci√≥n
    - ‚úì Configurar monitoreo en tiempo real
    - ‚úì Establecer proceso de reentrenamiento mensual
    - ‚úì Documentar procedimientos operativos
    """)

# Footer
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    st.info(f"**Modelo Evaluado:** XGBoost Champion")

with col2:
    st.info(f"**Fecha Reporte:** {datetime.now().strftime('%d/%m/%Y')}")

with col3:
    st.info(f"**Registros Test:** {len(results['test']['y_true'])}")

st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ü§ñ Sistema de Pron√≥stico Automatizado EPM | Generado con Streamlit<br>"
    "Empresa de Energ√≠a de Antioquia - 2024"
    "</div>",
    unsafe_allow_html=True
)
