"""
Motor de DesagregaciÃ³n Horaria Unificado

Este mÃ³dulo orquesta todo el sistema de desagregaciÃ³n horaria,
decidiendo automÃ¡ticamente quÃ© mÃ©todo usar segÃºn el tipo de dÃ­a.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Union
import logging

from .hourly_disaggregator import HourlyDisaggregator
from .special_days import SpecialDaysDisaggregator
from .calendar_utils import CalendarClassifier
from ...config.settings import MODELS_DIR

logger = logging.getLogger(__name__)


class HourlyDisaggregationEngine:
    """
    Motor unificado de desagregaciÃ³n horaria.

    Orquesta:
    1. ClasificaciÃ³n de dÃ­as (normal vs especial)
    2. SelecciÃ³n del desagregador apropiado
    3. GeneraciÃ³n de predicciones horarias
    4. ValidaciÃ³n de resultados
    """

    def __init__(
        self,
        normal_disaggregator: Optional[HourlyDisaggregator] = None,
        special_disaggregator: Optional[SpecialDaysDisaggregator] = None,
        auto_load: bool = True,
        models_dir: Optional[str] = None
    ):
        """
        Inicializa el motor de desagregaciÃ³n.

        Args:
            normal_disaggregator: Desagregador para dÃ­as normales (opcional)
            special_disaggregator: Desagregador para dÃ­as especiales (opcional)
            auto_load: Si True, intenta cargar modelos guardados automÃ¡ticamente
            models_dir: Directorio donde buscar los modelos (ej: 'models/Atlantico'). Si None, usa MODELS_DIR
        """
        self.calendar_classifier = CalendarClassifier()
        self.models_dir = Path(models_dir) if models_dir else Path(MODELS_DIR)

        # Cargar o usar desagregadores proporcionados
        if auto_load:
            self.normal_disaggregator = self._load_or_create(
                normal_disaggregator,
                HourlyDisaggregator,
                "hourly_disaggregator.pkl"
            )
            self.special_disaggregator = self._load_or_create(
                special_disaggregator,
                SpecialDaysDisaggregator,
                "special_days_disaggregator.pkl"
            )
        else:
            self.normal_disaggregator = normal_disaggregator
            self.special_disaggregator = special_disaggregator

    def _load_or_create(self, instance, cls, filename):
        """Intenta cargar modelo guardado o crear instancia nueva."""
        if instance is not None:
            return instance

        try:
            filepath = self.models_dir / filename
            if filepath.exists():
                logger.info(f"Cargando {filename} desde {filepath}...")
                return cls.load(filepath)
            else:
                logger.warning(f"No se encontrÃ³ {filename} en {self.models_dir}, creando instancia nueva (sin entrenar)")
                return cls()
        except Exception as e:
            logger.error(f"Error cargando {filename}: {e}")
            return cls()

    def predict_hourly(
        self,
        date: Union[str, pd.Timestamp],
        total_daily: float,
        validate: bool = True,
        return_senda: bool = True
    ) -> Dict:
        """
        Predice la distribuciÃ³n horaria para una fecha y total diario.

        Args:
            date: Fecha del pronÃ³stico
            total_daily: Demanda total del dÃ­a (MWh)
            validate: Si True, valida que la suma sea correcta
            return_senda: Si True, incluye patrÃ³n normalizado de referencia (senda)

        Returns:
            Dict con:
                - date: Fecha
                - total_daily: Total predicho
                - hourly: Array con distribuciÃ³n horaria (P1-P24)
                - senda_referencia: Array normalizado del cluster (0-1) [NUEVO]
                - cluster_id: ID del cluster usado [NUEVO]
                - method: MÃ©todo usado ("special" o "normal")
                - day_type: Tipo de dÃ­a
                - validation: Dict con informaciÃ³n de validaciÃ³n
        """
        date = pd.to_datetime(date)

        # Clasificar el dÃ­a
        day_info = self.calendar_classifier.get_full_classification(date)
        is_special = self.special_disaggregator.is_special_day(date) if self.special_disaggregator.is_fitted else False

        # Seleccionar mÃ©todo
        if is_special:
            method = "special"
            result = self.special_disaggregator.predict_hourly_profile(date, total_daily, return_normalized=return_senda)
            if return_senda and result is not None:
                hourly, senda_normalizada, cluster_id = result
            else:
                hourly = result
                senda_normalizada = None
                cluster_id = None
        else:
            method = "normal"
            if not self.normal_disaggregator.is_fitted:
                raise RuntimeError("El desagregador normal no estÃ¡ entrenado")
            result = self.normal_disaggregator.predict_hourly_profile(date, total_daily, return_normalized=return_senda)
            if return_senda:
                hourly, senda_normalizada, cluster_id = result
            else:
                hourly = result
                senda_normalizada = None
                cluster_id = None

        # ValidaciÃ³n
        validation = {
            'sum': hourly.sum(),
            'expected': total_daily,
            'difference': abs(hourly.sum() - total_daily),
            'relative_error': abs(hourly.sum() - total_daily) / total_daily * 100,
            'is_valid': abs(hourly.sum() - total_daily) < 0.01  # Tolerancia de 0.01 MWh
        }

        if validate and not validation['is_valid']:
            logger.warning(
                f"âš  ValidaciÃ³n fallida para {date.date()}: "
                f"suma={validation['sum']:.4f}, esperado={total_daily:.4f}"
            )

        response = {
            'date': date,
            'total_daily': total_daily,
            'hourly': hourly,
            'method': method,
            'day_type': day_info['tipo_dia'],
            'day_name': day_info['dia_semana'],
            'is_holiday': day_info['es_festivo'],
            'holiday_name': day_info['nombre_festivo'],
            'season': day_info['temporada'],
            'validation': validation
        }

        # Agregar senda si se solicitÃ³
        if return_senda and senda_normalizada is not None:
            response['senda_referencia'] = senda_normalizada
            response['cluster_id'] = int(cluster_id)

        return response

    def predict_batch(
        self,
        dates: pd.Series,
        totals_daily: pd.Series,
        return_dataframe: bool = True
    ) -> Union[pd.DataFrame, list]:
        """
        Predice distribuciones horarias para mÃºltiples fechas.

        Args:
            dates: Series de fechas
            totals_daily: Series de totales diarios
            return_dataframe: Si True, retorna DataFrame; si False, lista de dicts

        Returns:
            DataFrame o lista con predicciones horarias
        """
        if len(dates) != len(totals_daily):
            raise ValueError("dates y totals_daily deben tener la misma longitud")

        results = []
        for date, total in zip(dates, totals_daily):
            result = self.predict_hourly(date, total, validate=True)
            results.append(result)

        if return_dataframe:
            return self._results_to_dataframe(results)
        else:
            return results

    def _results_to_dataframe(self, results: list) -> pd.DataFrame:
        """Convierte lista de resultados a DataFrame."""
        rows = []
        for r in results:
            row = {
                'FECHA': r['date'],
                'TOTAL': r['total_daily'],
                'method': r['method'],
                'day_type': r['day_type'],
                'day_name': r['day_name'],
                'is_holiday': r['is_holiday'],
                'validation_ok': r['validation']['is_valid'],
                **{f'P{i}': r['hourly'][i-1] for i in range(1, 25)}
            }
            rows.append(row)

        return pd.DataFrame(rows)

    def get_engine_status(self) -> Dict:
        """
        Retorna el estado del motor de desagregaciÃ³n.

        Returns:
            Dict con informaciÃ³n de estado
        """
        return {
            'normal_disaggregator': {
                'fitted': self.normal_disaggregator.is_fitted,
                'n_clusters': self.normal_disaggregator.n_clusters if self.normal_disaggregator.is_fitted else None,
            },
            'special_disaggregator': {
                'fitted': self.special_disaggregator.is_fitted,
                'n_clusters': self.special_disaggregator.n_clusters if self.special_disaggregator.is_fitted else None,
                'n_special_days': len(self.special_disaggregator.cluster_by_date) if self.special_disaggregator.is_fitted else 0,
            }
        }

    def train_all(
        self,
        data_path: Optional[Path] = None,
        n_clusters_normal: int = 35,
        n_clusters_special: int = 15,
        save: bool = True,
        output_dir: Optional[str] = None
    ) -> None:
        """
        Entrena ambos desagregadores con datos histÃ³ricos.

        Args:
            data_path: Ruta a datos histÃ³ricos
            n_clusters_normal: Clusters para dÃ­as normales
            n_clusters_special: Clusters para dÃ­as especiales
            save: Si True, guarda modelos entrenados
            output_dir: Directorio donde guardar modelos (ej: 'models/Atlantico'). Si None, usa MODELS_DIR
        """
        logger.info("=" * 80)
        logger.info("ENTRENAMIENTO COMPLETO DEL SISTEMA DE DESAGREGACIÃ“N")
        logger.info("=" * 80)

        from ...config.settings import FEATURES_DATA_DIR

        if data_path is None:
            data_path = Path(FEATURES_DATA_DIR) / "data_with_features_latest.csv"

        logger.info(f"Cargando datos desde {data_path}...")
        df = pd.read_csv(data_path)
        print('d'*50)
        df.dropna(inplace=True)
        print(df.head())
        print('d'*50)
        # Determinar directorio de salida
        save_dir = Path(output_dir) if output_dir else self.models_dir
        print('c'*20)
        print(save_dir)
        print('c'*20)
        # Entrenar desagregador normal
        logger.info("\n1. Entrenando desagregador para dÃ­as normales...")
        self.normal_disaggregator = HourlyDisaggregator(n_clusters=n_clusters_normal)
        self.normal_disaggregator.fit(df, date_column='FECHA')

        if save:
            output_path = save_dir / "hourly_disaggregator.pkl"
            print('a'*20)
            print(output_path)
            print('a'*20)
            self.normal_disaggregator.save(output_path)
            logger.info(f"   âœ“ Guardado en {output_path}")

        # Entrenar desagregador especial
        logger.info("\n2. Entrenando desagregador para dÃ­as especiales...")
        self.special_disaggregator = SpecialDaysDisaggregator(n_clusters=n_clusters_special)
        self.special_disaggregator.fit(df, date_column='FECHA')

        if save:
            output_path = save_dir / "special_days_disaggregator.pkl"
            print('b'*20)
            print(output_path)
            print('b'*20)
            self.special_disaggregator.save(output_path)
            logger.info(f"   âœ“ Guardado en {output_path}")

        logger.info("\n" + "=" * 80)
        logger.info("âœ“ SISTEMA DE DESAGREGACIÃ“N ENTRENADO COMPLETAMENTE")
        logger.info("=" * 80)

        # Mostrar resumen
        status = self.get_engine_status()
        logger.info(f"\nResumen:")
        logger.info(f"  - DÃ­as normales: {status['normal_disaggregator']['n_clusters']} clusters")
        logger.info(f"  - DÃ­as especiales: {status['special_disaggregator']['n_clusters']} clusters")
        logger.info(f"  - Festivos conocidos: {status['special_disaggregator']['n_special_days']}")


# ============== EJEMPLO DE USO ==============

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    print("=" * 80)
    print("SISTEMA DE DESAGREGACIÃ“N HORARIA - EPM")
    print("=" * 80)

    # Crear motor
    engine = HourlyDisaggregationEngine(auto_load=True)

    # Verificar estado
    status = engine.get_engine_status()
    print("\nðŸ“Š Estado del sistema:")
    print(f"  Normal: {'âœ“ Entrenado' if status['normal_disaggregator']['fitted'] else 'âœ— No entrenado'}")
    print(f"  Especial: {'âœ“ Entrenado' if status['special_disaggregator']['fitted'] else 'âœ— No entrenado'}")

    # Si no estÃ¡ entrenado, entrenar
    if not (status['normal_disaggregator']['fitted'] and status['special_disaggregator']['fitted']):
        print("\nðŸ”§ Entrenando sistema...")
        engine.train_all(n_clusters_normal=35, n_clusters_special=15, save=True)

    # Probar predicciones
    print("\n" + "=" * 80)
    print("PREDICCIONES DE PRUEBA")
    print("=" * 80)

    test_cases = [
        ("2024-03-15", 1500.0, "Viernes normal"),
        ("2024-03-17", 1200.0, "Domingo"),
        ("2024-12-25", 1100.0, "Navidad"),
        ("2024-01-01", 1050.0, "AÃ±o Nuevo"),
    ]

    for date_str, total, description in test_cases:
        result = engine.predict_hourly(date_str, total)

        print(f"\nðŸ“… {description} ({date_str})")
        print(f"   Tipo: {result['day_type']} | MÃ©todo: {result['method']}")
        print(f"   Total: {total} MWh")
        print(f"   Suma horaria: {result['validation']['sum']:.2f} MWh")
        print(f"   Diferencia: {result['validation']['difference']:.6f} MWh")
        print(f"   ValidaciÃ³n: {'âœ“ OK' if result['validation']['is_valid'] else 'âœ— FALLO'}")

    print("\n" + "=" * 80)
